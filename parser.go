// Package fileparser provides file parsing functionality for various tabular data formats.
// It supports CSV, TSV, LTSV, XLSX, and Parquet files, with optional compression
// (gzip, bzip2, xz, zstd).
//
// This package can be used by filesql, fileprep, fileframe, or any application
// that needs to parse tabular data files.
//
// # Memory Considerations
//
// All parsing functions in this package load the entire dataset into memory.
// This design is intentional for simplicity and compatibility with formats that
// require random access (Parquet, XLSX), but has implications for large files:
//
//   - CSV/TSV/LTSV: Entire file content is read into memory
//   - XLSX: Entire workbook is loaded (Excel files can be large even with few rows)
//   - Parquet: Entire file is read into memory for random access
//
// For files larger than available memory, consider:
//   - Using streaming APIs for CSV/TSV
//   - Pre-filtering or splitting large files before processing
//   - Increasing available memory for the process
//
// # Example usage
//
//	f, _ := os.Open("data.csv")
//	defer f.Close()
//	result, err := fileparser.Parse(f, fileparser.CSV)
//	if err != nil {
//	    log.Fatal(err)
//	}
//	fmt.Println("Columns:", result.Headers)
//	fmt.Println("Rows:", len(result.Records))
//
// # Type Conversion
//
// Use [ParseValue] to convert string records to typed Go values based on [ColumnType].
package fileparser

import (
	"compress/bzip2"
	"compress/gzip"
	"compress/zlib"
	"encoding/csv"
	"errors"
	"fmt"
	"io"
	"path/filepath"
	"strings"

	"github.com/klauspost/compress/s2"
	"github.com/klauspost/compress/snappy"
	"github.com/klauspost/compress/zstd"
	"github.com/pierrec/lz4/v4"
	"github.com/ulikunitz/xz"
)

// FileType represents supported file types including compression variants.
type FileType int

const (
	// CSV represents CSV file type.
	CSV FileType = iota
	// TSV represents TSV file type.
	TSV
	// LTSV represents LTSV (Labeled Tab-Separated Values) file type.
	LTSV
	// Parquet represents Apache Parquet file type.
	Parquet
	// XLSX represents Excel XLSX file type.
	XLSX

	// CSVGZ represents gzip-compressed CSV file type.
	CSVGZ
	// CSVBZ2 represents bzip2-compressed CSV file type.
	CSVBZ2
	// CSVXZ represents xz-compressed CSV file type.
	CSVXZ
	// CSVZSTD represents zstd-compressed CSV file type.
	CSVZSTD

	// TSVGZ represents gzip-compressed TSV file type.
	TSVGZ
	// TSVBZ2 represents bzip2-compressed TSV file type.
	TSVBZ2
	// TSVXZ represents xz-compressed TSV file type.
	TSVXZ
	// TSVZSTD represents zstd-compressed TSV file type.
	TSVZSTD

	// LTSVGZ represents gzip-compressed LTSV file type.
	LTSVGZ
	// LTSVBZ2 represents bzip2-compressed LTSV file type.
	LTSVBZ2
	// LTSVXZ represents xz-compressed LTSV file type.
	LTSVXZ
	// LTSVZSTD represents zstd-compressed LTSV file type.
	LTSVZSTD

	// ParquetGZ represents gzip-compressed Parquet file type.
	ParquetGZ
	// ParquetBZ2 represents bzip2-compressed Parquet file type.
	ParquetBZ2
	// ParquetXZ represents xz-compressed Parquet file type.
	ParquetXZ
	// ParquetZSTD represents zstd-compressed Parquet file type.
	ParquetZSTD

	// XLSXGZ represents gzip-compressed XLSX file type.
	XLSXGZ
	// XLSXBZ2 represents bzip2-compressed XLSX file type.
	XLSXBZ2
	// XLSXXZ represents xz-compressed XLSX file type.
	XLSXXZ
	// XLSXZSTD represents zstd-compressed XLSX file type.
	XLSXZSTD

	// CSVZLIB represents zlib-compressed CSV file type.
	CSVZLIB
	// TSVZLIB represents zlib-compressed TSV file type.
	TSVZLIB
	// LTSVZLIB represents zlib-compressed LTSV file type.
	LTSVZLIB
	// ParquetZLIB represents zlib-compressed Parquet file type.
	ParquetZLIB
	// XLSXZLIB represents zlib-compressed XLSX file type.
	XLSXZLIB

	// CSVSNAPPY represents snappy-compressed CSV file type.
	CSVSNAPPY
	// TSVSNAPPY represents snappy-compressed TSV file type.
	TSVSNAPPY
	// LTSVSNAPPY represents snappy-compressed LTSV file type.
	LTSVSNAPPY
	// ParquetSNAPPY represents snappy-compressed Parquet file type.
	ParquetSNAPPY
	// XLSXSNAPPY represents snappy-compressed XLSX file type.
	XLSXSNAPPY

	// CSVS2 represents s2-compressed CSV file type.
	CSVS2
	// TSVS2 represents s2-compressed TSV file type.
	TSVS2
	// LTSVS2 represents s2-compressed LTSV file type.
	LTSVS2
	// ParquetS2 represents s2-compressed Parquet file type.
	ParquetS2
	// XLSXS2 represents s2-compressed XLSX file type.
	XLSXS2

	// CSVLZ4 represents lz4-compressed CSV file type.
	CSVLZ4
	// TSVLZ4 represents lz4-compressed TSV file type.
	TSVLZ4
	// LTSVLZ4 represents lz4-compressed LTSV file type.
	LTSVLZ4
	// ParquetLZ4 represents lz4-compressed Parquet file type.
	ParquetLZ4
	// XLSXLZ4 represents lz4-compressed XLSX file type.
	XLSXLZ4

	// Unsupported represents unsupported file type.
	Unsupported
)

// String returns a human-readable string representation of the FileType.
func (ft FileType) String() string {
	switch ft {
	case CSV:
		return "CSV"
	case TSV:
		return "TSV"
	case LTSV:
		return "LTSV"
	case Parquet:
		return "Parquet"
	case XLSX:
		return "XLSX"
	case CSVGZ:
		return "CSV (gzip)"
	case CSVBZ2:
		return "CSV (bzip2)"
	case CSVXZ:
		return "CSV (xz)"
	case CSVZSTD:
		return "CSV (zstd)"
	case TSVGZ:
		return "TSV (gzip)"
	case TSVBZ2:
		return "TSV (bzip2)"
	case TSVXZ:
		return "TSV (xz)"
	case TSVZSTD:
		return "TSV (zstd)"
	case LTSVGZ:
		return "LTSV (gzip)"
	case LTSVBZ2:
		return "LTSV (bzip2)"
	case LTSVXZ:
		return "LTSV (xz)"
	case LTSVZSTD:
		return "LTSV (zstd)"
	case ParquetGZ:
		return "Parquet (gzip)"
	case ParquetBZ2:
		return "Parquet (bzip2)"
	case ParquetXZ:
		return "Parquet (xz)"
	case ParquetZSTD:
		return "Parquet (zstd)"
	case XLSXGZ:
		return "XLSX (gzip)"
	case XLSXBZ2:
		return "XLSX (bzip2)"
	case XLSXXZ:
		return "XLSX (xz)"
	case XLSXZSTD:
		return "XLSX (zstd)"
	case CSVZLIB:
		return "CSV (zlib)"
	case TSVZLIB:
		return "TSV (zlib)"
	case LTSVZLIB:
		return "LTSV (zlib)"
	case ParquetZLIB:
		return "Parquet (zlib)"
	case XLSXZLIB:
		return "XLSX (zlib)"
	case CSVSNAPPY:
		return "CSV (snappy)"
	case TSVSNAPPY:
		return "TSV (snappy)"
	case LTSVSNAPPY:
		return "LTSV (snappy)"
	case ParquetSNAPPY:
		return "Parquet (snappy)"
	case XLSXSNAPPY:
		return "XLSX (snappy)"
	case CSVS2:
		return "CSV (s2)"
	case TSVS2:
		return "TSV (s2)"
	case LTSVS2:
		return "LTSV (s2)"
	case ParquetS2:
		return "Parquet (s2)"
	case XLSXS2:
		return "XLSX (s2)"
	case CSVLZ4:
		return "CSV (lz4)"
	case TSVLZ4:
		return "TSV (lz4)"
	case LTSVLZ4:
		return "LTSV (lz4)"
	case ParquetLZ4:
		return "Parquet (lz4)"
	case XLSXLZ4:
		return "XLSX (lz4)"
	default:
		return "Unsupported"
	}
}

// ColumnType represents the inferred type of a column.
type ColumnType int

const (
	// TypeText represents text/string column type.
	TypeText ColumnType = iota
	// TypeInteger represents integer column type.
	TypeInteger
	// TypeReal represents floating-point column type.
	TypeReal
	// TypeDatetime represents datetime column type.
	TypeDatetime
)

// String returns the string representation of ColumnType.
func (ct ColumnType) String() string {
	switch ct {
	case TypeText:
		return "TEXT"
	case TypeInteger:
		return "INTEGER"
	case TypeReal:
		return "REAL"
	case TypeDatetime:
		return "DATETIME"
	default:
		return "TEXT"
	}
}

// TableData contains the parsed data from a file.
type TableData struct {
	// Headers contains the column names in order.
	Headers []string
	// Records contains the data rows. Each record is a slice of string values.
	Records [][]string
	// ColumnTypes contains the inferred types for each column.
	// The length matches Headers.
	ColumnTypes []ColumnType
}

// Parse reads data from an io.Reader and returns parsed results.
// The fileType parameter specifies the format and compression of the data.
//
// Example:
//
//	f, _ := os.Open("data.csv.gz")
//	defer f.Close()
//	result, err := fileparser.Parse(f, fileparser.CSVGZ)
func Parse(reader io.Reader, fileType FileType) (result *TableData, err error) {
	if reader == nil {
		return nil, errors.New("reader cannot be nil")
	}

	// Handle decompression
	decompressedReader, closeFunc, decompErr := createDecompressedReader(reader, fileType)
	if decompErr != nil {
		return nil, fmt.Errorf("failed to decompress: %w", decompErr)
	}
	if closeFunc != nil {
		defer func() {
			if closeErr := closeFunc(); closeErr != nil && err == nil {
				err = fmt.Errorf("failed to close decompressor: %w", closeErr)
			}
		}()
	}

	// Parse based on base file type
	baseType := BaseFileType(fileType)
	switch baseType {
	case CSV:
		return parseDelimited(decompressedReader, ',', "CSV")
	case TSV:
		return parseDelimited(decompressedReader, '\t', "TSV")
	case LTSV:
		return parseLTSV(decompressedReader)
	case Parquet:
		return parseParquet(decompressedReader)
	case XLSX:
		return parseXLSX(decompressedReader)
	default:
		return nil, errors.New("unsupported file type")
	}
}

// File extensions
const (
	ExtCSV     = ".csv"
	ExtTSV     = ".tsv"
	ExtLTSV    = ".ltsv"
	ExtParquet = ".parquet"
	ExtXLSX    = ".xlsx"
	ExtGZ      = ".gz"
	ExtBZ2     = ".bz2"
	ExtXZ      = ".xz"
	ExtZSTD    = ".zst"
	ExtZLIB    = ".z"
	ExtSNAPPY  = ".snappy"
	ExtS2      = ".s2"
	ExtLZ4     = ".lz4"
)

// Compression type identifiers
const (
	compGZ     = "gz"
	compBZ2    = "bz2"
	compXZ     = "xz"
	compZSTD   = "zstd"
	compZLIB   = "zlib"
	compSNAPPY = "snappy"
	compS2     = "s2"
	compLZ4    = "lz4"
)

// DetectFileType detects file type from path extension, including compression variants.
func DetectFileType(path string) FileType {
	basePath := path
	var compressionType string

	// Remove compression extensions
	lowerPath := strings.ToLower(path)
	switch {
	case strings.HasSuffix(lowerPath, ExtGZ):
		basePath = path[:len(path)-len(ExtGZ)]
		compressionType = compGZ
	case strings.HasSuffix(lowerPath, ExtBZ2):
		basePath = path[:len(path)-len(ExtBZ2)]
		compressionType = compBZ2
	case strings.HasSuffix(lowerPath, ExtXZ):
		basePath = path[:len(path)-len(ExtXZ)]
		compressionType = compXZ
	case strings.HasSuffix(lowerPath, ExtZSTD):
		basePath = path[:len(path)-len(ExtZSTD)]
		compressionType = compZSTD
	case strings.HasSuffix(lowerPath, ExtZLIB):
		basePath = path[:len(path)-len(ExtZLIB)]
		compressionType = compZLIB
	case strings.HasSuffix(lowerPath, ExtSNAPPY):
		basePath = path[:len(path)-len(ExtSNAPPY)]
		compressionType = compSNAPPY
	case strings.HasSuffix(lowerPath, ExtS2):
		basePath = path[:len(path)-len(ExtS2)]
		compressionType = compS2
	case strings.HasSuffix(lowerPath, ExtLZ4):
		basePath = path[:len(path)-len(ExtLZ4)]
		compressionType = compLZ4
	}

	ext := strings.ToLower(filepath.Ext(basePath))
	switch ext {
	case ExtCSV:
		switch compressionType {
		case compGZ:
			return CSVGZ
		case compBZ2:
			return CSVBZ2
		case compXZ:
			return CSVXZ
		case compZSTD:
			return CSVZSTD
		case compZLIB:
			return CSVZLIB
		case compSNAPPY:
			return CSVSNAPPY
		case compS2:
			return CSVS2
		case compLZ4:
			return CSVLZ4
		default:
			return CSV
		}
	case ExtTSV:
		switch compressionType {
		case compGZ:
			return TSVGZ
		case compBZ2:
			return TSVBZ2
		case compXZ:
			return TSVXZ
		case compZSTD:
			return TSVZSTD
		case compZLIB:
			return TSVZLIB
		case compSNAPPY:
			return TSVSNAPPY
		case compS2:
			return TSVS2
		case compLZ4:
			return TSVLZ4
		default:
			return TSV
		}
	case ExtLTSV:
		switch compressionType {
		case compGZ:
			return LTSVGZ
		case compBZ2:
			return LTSVBZ2
		case compXZ:
			return LTSVXZ
		case compZSTD:
			return LTSVZSTD
		case compZLIB:
			return LTSVZLIB
		case compSNAPPY:
			return LTSVSNAPPY
		case compS2:
			return LTSVS2
		case compLZ4:
			return LTSVLZ4
		default:
			return LTSV
		}
	case ExtParquet:
		switch compressionType {
		case compGZ:
			return ParquetGZ
		case compBZ2:
			return ParquetBZ2
		case compXZ:
			return ParquetXZ
		case compZSTD:
			return ParquetZSTD
		case compZLIB:
			return ParquetZLIB
		case compSNAPPY:
			return ParquetSNAPPY
		case compS2:
			return ParquetS2
		case compLZ4:
			return ParquetLZ4
		default:
			return Parquet
		}
	case ExtXLSX:
		switch compressionType {
		case compGZ:
			return XLSXGZ
		case compBZ2:
			return XLSXBZ2
		case compXZ:
			return XLSXXZ
		case compZSTD:
			return XLSXZSTD
		case compZLIB:
			return XLSXZLIB
		case compSNAPPY:
			return XLSXSNAPPY
		case compS2:
			return XLSXS2
		case compLZ4:
			return XLSXLZ4
		default:
			return XLSX
		}
	default:
		return Unsupported
	}
}

// IsCompressed returns true if the file type is compressed.
func IsCompressed(ft FileType) bool {
	switch ft {
	case CSVGZ, CSVBZ2, CSVXZ, CSVZSTD, CSVZLIB, CSVSNAPPY, CSVS2, CSVLZ4,
		TSVGZ, TSVBZ2, TSVXZ, TSVZSTD, TSVZLIB, TSVSNAPPY, TSVS2, TSVLZ4,
		LTSVGZ, LTSVBZ2, LTSVXZ, LTSVZSTD, LTSVZLIB, LTSVSNAPPY, LTSVS2, LTSVLZ4,
		ParquetGZ, ParquetBZ2, ParquetXZ, ParquetZSTD, ParquetZLIB, ParquetSNAPPY, ParquetS2, ParquetLZ4,
		XLSXGZ, XLSXBZ2, XLSXXZ, XLSXZSTD, XLSXZLIB, XLSXSNAPPY, XLSXS2, XLSXLZ4:
		return true
	default:
		return false
	}
}

// BaseFileType returns the base file type without compression.
func BaseFileType(ft FileType) FileType {
	switch ft {
	case CSV, CSVGZ, CSVBZ2, CSVXZ, CSVZSTD, CSVZLIB, CSVSNAPPY, CSVS2, CSVLZ4:
		return CSV
	case TSV, TSVGZ, TSVBZ2, TSVXZ, TSVZSTD, TSVZLIB, TSVSNAPPY, TSVS2, TSVLZ4:
		return TSV
	case LTSV, LTSVGZ, LTSVBZ2, LTSVXZ, LTSVZSTD, LTSVZLIB, LTSVSNAPPY, LTSVS2, LTSVLZ4:
		return LTSV
	case Parquet, ParquetGZ, ParquetBZ2, ParquetXZ, ParquetZSTD, ParquetZLIB, ParquetSNAPPY, ParquetS2, ParquetLZ4:
		return Parquet
	case XLSX, XLSXGZ, XLSXBZ2, XLSXXZ, XLSXZSTD, XLSXZLIB, XLSXSNAPPY, XLSXS2, XLSXLZ4:
		return XLSX
	default:
		return Unsupported
	}
}

// createDecompressedReader wraps the reader with appropriate decompression.
func createDecompressedReader(reader io.Reader, fileType FileType) (io.Reader, func() error, error) {
	switch fileType {
	case CSVGZ, TSVGZ, LTSVGZ, XLSXGZ, ParquetGZ:
		gzReader, err := gzip.NewReader(reader)
		if err != nil {
			return nil, nil, fmt.Errorf("failed to create gzip reader: %w", err)
		}
		return gzReader, func() error { return gzReader.Close() }, nil

	case CSVBZ2, TSVBZ2, LTSVBZ2, XLSXBZ2, ParquetBZ2:
		bz2Reader := bzip2.NewReader(reader)
		return bz2Reader, nil, nil

	case CSVXZ, TSVXZ, LTSVXZ, XLSXXZ, ParquetXZ:
		xzReader, err := xz.NewReader(reader)
		if err != nil {
			return nil, nil, fmt.Errorf("failed to create xz reader: %w", err)
		}
		return xzReader, nil, nil

	case CSVZSTD, TSVZSTD, LTSVZSTD, XLSXZSTD, ParquetZSTD:
		decoder, err := zstd.NewReader(reader)
		if err != nil {
			return nil, nil, fmt.Errorf("failed to create zstd reader: %w", err)
		}
		return decoder, func() error { decoder.Close(); return nil }, nil

	case CSVZLIB, TSVZLIB, LTSVZLIB, XLSXZLIB, ParquetZLIB:
		zlibReader, err := zlib.NewReader(reader)
		if err != nil {
			return nil, nil, fmt.Errorf("failed to create zlib reader: %w", err)
		}
		return zlibReader, func() error { return zlibReader.Close() }, nil

	case CSVSNAPPY, TSVSNAPPY, LTSVSNAPPY, XLSXSNAPPY, ParquetSNAPPY:
		snappyReader := snappy.NewReader(reader)
		return snappyReader, nil, nil

	case CSVS2, TSVS2, LTSVS2, XLSXS2, ParquetS2:
		s2Reader := s2.NewReader(reader)
		return s2Reader, nil, nil

	case CSVLZ4, TSVLZ4, LTSVLZ4, XLSXLZ4, ParquetLZ4:
		lz4Reader := lz4.NewReader(reader)
		return lz4Reader, nil, nil

	default:
		// No compression
		return reader, nil, nil
	}
}

// parseDelimited parses CSV or TSV data.
func parseDelimited(reader io.Reader, delimiter rune, fileTypeName string) (*TableData, error) {
	csvReader := csv.NewReader(reader)
	csvReader.Comma = delimiter

	records, err := csvReader.ReadAll()
	if err != nil {
		return nil, fmt.Errorf("failed to read %s: %w", fileTypeName, err)
	}

	if len(records) == 0 {
		return nil, fmt.Errorf("empty %s data", fileTypeName)
	}

	headers := records[0]
	if err := validateColumnNames(headers); err != nil {
		return nil, err
	}

	dataRecords := make([][]string, 0, len(records)-1)
	for i := 1; i < len(records); i++ {
		dataRecords = append(dataRecords, records[i])
	}

	// Infer column types
	columnTypes := inferColumnTypes(headers, dataRecords)

	return &TableData{
		Headers:     headers,
		Records:     dataRecords,
		ColumnTypes: columnTypes,
	}, nil
}

// parseLTSV parses LTSV (Labeled Tab-Separated Values) data.
// Column order is preserved as first-seen order for deterministic output.
func parseLTSV(reader io.Reader) (*TableData, error) {
	content, err := io.ReadAll(reader)
	if err != nil {
		return nil, fmt.Errorf("failed to read LTSV: %w", err)
	}

	lines := strings.Split(string(content), "\n")
	if len(lines) == 0 {
		return nil, errors.New("empty LTSV data")
	}

	// Use slice to preserve first-seen order
	var headers []string
	headerSeen := make(map[string]bool)
	var parsedRecords []map[string]string

	for _, line := range lines {
		line = strings.TrimSpace(line)
		if line == "" {
			continue
		}

		recordMap := make(map[string]string)
		pairs := strings.Split(line, "\t")
		for _, pair := range pairs {
			kv := strings.SplitN(pair, ":", 2)
			if len(kv) == 2 {
				key := strings.TrimSpace(kv[0])
				value := strings.TrimSpace(kv[1])
				recordMap[key] = value
				// Track headers in first-seen order
				if !headerSeen[key] {
					headerSeen[key] = true
					headers = append(headers, key)
				}
			}
		}
		if len(recordMap) > 0 {
			parsedRecords = append(parsedRecords, recordMap)
		}
	}

	if len(parsedRecords) == 0 {
		return nil, errors.New("no valid LTSV records found")
	}

	// Convert to records using first-seen header order
	records := make([][]string, 0, len(parsedRecords))
	for _, recordMap := range parsedRecords {
		row := make([]string, len(headers))
		for i, key := range headers {
			if val, exists := recordMap[key]; exists {
				row[i] = val
			} else {
				row[i] = ""
			}
		}
		records = append(records, row)
	}

	// Infer column types
	columnTypes := inferColumnTypes(headers, records)

	return &TableData{
		Headers:     headers,
		Records:     records,
		ColumnTypes: columnTypes,
	}, nil
}

// validateColumnNames checks for duplicate column names.
func validateColumnNames(columns []string) error {
	seen := make(map[string]bool, len(columns))
	for _, col := range columns {
		if seen[col] {
			return fmt.Errorf("duplicate column name: %s", col)
		}
		seen[col] = true
	}
	return nil
}
